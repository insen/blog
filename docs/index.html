<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Insen &middot; Write, Code, Dream !
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="https://insen.github.io/blog/public/css/poole.css">
  <link rel="stylesheet" href="https://insen.github.io/blog/public/css/syntax.css">
  <link rel="stylesheet" href="https://insen.github.io/blog/public/css/hyde.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://insen.github.io/blog/public/apple-touch-icon-144-precomposed.png">
                                 <link rel="shortcut icon" href="https://insen.github.io/blog/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>


  <body>

    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="https://insen.github.io/blog/">
          Insen
        </a>
      </h1>
      <p class="lead">Write, Code, Dream ! <a href="https://github.com/insen" target="_blank">@insen</a>.</p>
    </div>

    <nav class="sidebar-nav">
      <a class="sidebar-nav-item" href="https://insen.github.io/blog/">Home</a>

      

      
      
        
          
        
      
        
          
            <a class="sidebar-nav-item" href="/E:/work/blogging/blog/./docs/about.html">About</a>
          
        
      
        
          
        
      
        
          
        
      
        
      
        
      
        
          
        
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      

      <a class="sidebar-nav-item" href="https://github.com/insen">@Github</a>
      <a class="sidebar-nav-item" href="https://linkedin.com/nilsengupta">@LinkedIn</a>
      <a class="sidebar-nav-item" href="mailto:indranil.sengupta@gmail.com">@gmail</a>
      <span class="sidebar-nav-item">Currently v1.0.0</span>
    </nav>

    <p>&copy; 2017. All rights reserved.</p>
  </div>
</div>


    <div class="content container">
      <div class="posts">
  
  
  <div class="post">
    <h1 class="post-title">
      <a href="https://insen.github.io/blog/2017/09/27/DevOps-Making-A-Start/">
        DevOps - Making a Start !
      </a>
    </h1>

    <span class="post-date">27 Sep 2017</span>

    <p>DevOps is everywhere these days. As it should be, yes. Yet that doesn't take anything away from the fact that DevOps is a difficult concept to understand and implement. The principles are fair and easy enough to grasp, but then the <em>where to begin</em> question comes in, and that is a very difficult question for something as nebulous as DevOps.</p>
<p>So how does one start being 'DevOps'y?  What drives DevOps?</p>
<h2>Context, Culture, Tools, Change, Automation, Feedback Loops and Collaboration !</h2>
<p>The above set summarizes the key drivers of DevOps anywhere. Additionally, there are a small but definite set of foundational DevOps practises, which have been proven enablers of DevOps over time.</p>
<h2>Foundational DevOps Practises</h2>
<ul>
<li>One touch build - <em>there should be a single command to build and package the tested version of a system.</em></li>
<li>One touch deploy - <em>there should be a single command to deploy a tried and tested version to an environment.</em></li>
<li>Automation - <em>everything repetitive should be automated.</em></li>
<li>Monitoring Dashboards - <em>all process information, tests, builds, deploys, operations, features, analytics should be monitored and available.</em></li>
</ul>
<p>Essentially, the practises above together cumulate into a CI/CD pipeline. How sophisticated/refined your CI/CD pipeline is, is one of the key technological measures of a DevOps oriented teams' maturity level.</p>
<p>So then the question driving a group trying to adopt a DevOps-y approach to software service delivery is, most likely, this</p>
<h2>Our DevOps Question</h2>
<p><em>Given our current context, what culture, practises and tools should I adopt which will enable</em></p>
<ul>
<li><em><strong>faster change adoption</strong>?</em></li>
<li><em><strong>more automation</strong>?</em></li>
<li><em><strong>more shared process information</strong>?</em></li>
<li><em><strong>more closed feedback loops</strong>?</em></li>
</ul>
<p><em>Note : Remember this question, We'll come back to this time and again.</em></p>
<p>If we formulate an answer to the question above, we should have a workable Devops Strategy 101. Let us try an exercise and see.</p>
<h2>Setting the '<em>Context</em>'</h2>
<p><strong>Context</strong> is all about <em>NOT</em> sacrificing global optima to achieve local optima. <em>But then my junior dev comes up, the one I hired last month, saying he doesn't know what the ceo knows so he doesn't have all the context so he can't code a-la DevOps.</em></p>
<p>Oops!</p>
<p>That didn't sound legit, did it? Cos it wasn't. In DevOps context itself is context-sensitive, i.e. it means take the biggest picture from where you stand. That's all you can do anyways.</p>
<p>Since context is king, we will set a context. Assume the following organizational scenario within which to start out on a DevOps analysis first.</p>
<p><em>A team trying to provide custom software development and integration services on Azure. A team trying to a create a distributed processing layer for the .NET Stack system. A team working on big-data analytics and data presentation system on Azure. A management team trying to manage all these.</em></p>
<p><em>Also assume that all of the teams have various degrees of maturity on the build, test, deploy aspects of their individual systems - so effectively, automated builds, automated tests, and CI/CD exists, but to various degrees. Which is usually the case in diverse organizations.</em></p>
<p>So the context here is a bunch of <em>software engineers trying to provide system development services on Azure</em>.</p>
<p>Next.</p>
<h2>Consider 'Culture'</h2>
<p>Now what can we do about Culture here?</p>
<p>Well, in a software development group, there is one <em>'Culture'</em> culture, or group culture or organization culture.</p>
<p>Now this top-level culture is probably not something everybody can start off with. But in every culture, there are sub-cultures. And there are sub-cultures across development tools, eco-systems or resources. <em>(Java vs .Net, anyone?)</em>. So for a start, let's just pick a culture by eco-system. Since Azure is common across, let's pick Azure.</p>
<p>Enter <em><strong>Azure Culture</strong></em>. But what does <em>Azure Culture</em> in a DevOps organization mean? Let's go back and see how our original question changes.</p>
<p><em>What practises and tools should I adopt which will enable</em></p>
<ul>
<li><em><strong>faster change adoption</strong> in Azure?</em></li>
<li><em><strong>more automation</strong> in Azure?</em></li>
<li><em><strong>more shared process</strong> information in Azure?</em></li>
<li><em><strong>more closed feedback</strong> loops in Azure?</em></li>
</ul>
<p><em>Note - Should we limit ourselves to Azure specific tools. What if we work on Scala, Node, .NET? So perhaps, we need to analyse tooling more comprehensively.</em></p>
<p><em>The above is the kind of question that completely derails initiatives if we sit down to exhaustively analyse the options. Sometime you just pick the first option and go - just so that it sets an operational context, if nothing else.</em></p>
<p>We will just set one - the .NET stack. <em>Keeping things within the family, you see. You pick scala, or hadoop or node as per your needs. After all, you need multiple iterations of this.</em></p>
<p>So our task has now decomposed into a search for tooling options on the Azure platform and the .NET software development stack that enables foundational DevOps practises while achieving one or more of our goals - <em>faster change adoption, more automation,more shared process information, more closed feedback loops</em>. Once we identify tools and technologies, we <em>assess our maturity levels on identified tools and practises</em> to <em>identify <strong>gaps</strong> which can be plugged</em>.</p>
<p><strong>The gaps are what we attack in our DevOps strategy 101</strong>. The number of iterations of this process you go through, and the reviews with all concerned stakeholders should pare the list to items with highest priority overall.</p>
<p>Now we will do a non technical map-reduce. In <em>map</em> phase, we list out every possible tool, practise or activity that looks like it might help. In <em>reduce</em> phase - we prioritize items from list.</p>
<p>And in map phase our goals are simple.</p>
<ul>
<li><em><strong>tools we can adopt</strong></em></li>
<li><em><strong>practises we can encourage</strong></em></li>
<li><em><strong>activities we can do</strong></em></li>
</ul>
<p>Now, the initial list will probably be large, as both Azure nor Microsoft .NET are huge eco-systems, but remember two things,</p>
<ul>
<li>We are just looking for what to start with.</li>
<li>As of now, we are just identifying as many options as we can that are applicable.</li>
</ul>
<p>But we do need to manage, classify and process this list. Wikipedia, in its DevOps page, suggests the SDLC stages - Code, Test, Build/Package/Relase (<em>merged these as boundaries between them are overlapping, especially in the matter of tooling</em>), and Monitor.</p>
<h3>Azure/.NET Stack | SDLC Stage - Code</h3>
<p>A basic DevOps practises here is <em>Version Control</em>. Distributed VCS are now standard, so we pick <em><strong>Git</strong></em>.</p>
<p>Architectural support targeting DevOps enablement for Azure PaaS systems is a much-needed eco-system centric practise. Enter <em><strong>Microservice architectures</strong></em> which by encouraging by encouraging small pieces and plug-and-play composition help keeping pieces small and nimble.</p>
<p><em><strong>Test-Driven Design (TDD)</strong></em> and <em><strong>Domain Driven Design (DDD)</strong></em> are other standard practises that help in better code, decoupled pieces.</p>
<h4>Tools</h4>
<ul>
<li>Git.</li>
</ul>
<h4>Practises</h4>
<ul>
<li>Test Driven Design (TDD)</li>
<li>Domain Driven Design (DDD)</li>
<li>Microservices architectural style</li>
</ul>
<h3>Azure/.NET Stack | SDLC Stage - Test</h3>
<p>Test automation has several flavours</p>
<ul>
<li>Unit Tests</li>
<li>Integration Tests</li>
<li>Performance tests.</li>
</ul>
<p>Additionally, we can also automate the test generation process through Behavior Driven Design Tools like SpecFlow. And test execution automation is usually done through build pipelines and Continuous Integration (CI)/Continuous Delivery(CD).</p>
<h4>Tools</h4>
<ul>
<li><a href="https://docs.microsoft.com/en-us/visualstudio/test/intellitest-manual/introduction">Pex - Generates boundary conditions tests</a></li>
<li>Unit And Integrated Testing Frameworks</li>
<li>Identify Metrics and tools to report Metrics - NCover, Ndepend, Ncrunch</li>
<li><strong>Azure Dev/Test Labs</strong></li>
</ul>
<p>Some possible activities. The one around <em>logging formats</em> and <em>test reports</em> is especially interesting -</p>
<h4>Activities</h4>
<ul>
<li><em><strong>There seems to be no standards in the world around Logging formats and Test reports</strong></em>.</li>
<li>Persona based metrics - <em>who needs what metrics?</em></li>
<li>Automation ROI graphs - <em>how to demonstrate?</em></li>
<li>How to enable specification to final product traceability?</li>
</ul>
<h3>Azure .NET Stack | SDLC Stage - Build/Package/Release</h3>
<p>In this section, practises are common across software development verticals and horizontals.</p>
<h4>Practises</h4>
<ul>
<li>One Touch Build and Deploys.</li>
<li>Build Pipelines - Same builds on dev and test machines, Setup builds and Automated local deployment.</li>
<li>Automated provisioning <em>(Infrastructure configuration and management and Infrastructure as Code tools)</em></li>
</ul>
<h4>Tools</h4>
<p>These include</p>
<ul>
<li>Automation tools (in and out-system) - Powershell, MSDeploy,  Puppet, Chef, Docker, Ansible, OctopusDeploy.</li>
<li>Build tools and Servers (in and out-system) - MSBuild, PSake, DACPAC, TeamCity, Jenkins.</li>
<li>Eco System specific tools - Azure Resource Management (ARM) Templates and Azure CLI.</li>
</ul>
<h3>Azure/.NET Stack | SDLC Stage - Monitor</h3>
<p>This is probably a big problem area. For now we will gloss over it, but in practise, we would now probably take just monitoring as a problem area for DevOps and resort to the same technique we used throughout this post to break that down into tools, practises and activities.</p>
<h4>Practises</h4>
<p>What is needed here is feedback loops and operation trend monitoring through shared dashboards. To large extents, these feedback loops across localized scope (from a DevOps point of view) can be provided by ALM tools like JIRA on the scope and requirements and features perspective, while build and test feedback loops can be provided by CI servers and build-pipelines.</p>
<p>The difficult part is actually setting up on what to record and monitor. Sifting noise from signal here is a significant and <em>not-always-technical</em> step. And once past this, we have the technically demanding part in setting up a system which integrates separate local scopes into integrated dashboards. That is hard and definitely not DevOps 101. Maybe later.</p>
<p>Tools include VSTS - for application life-cycle management, Azure AppInsight for application operation management, standard external tools like NewRelic, and ELK, advanced services like Azure OMS (native) and Google Analytics (external).</p>
<h4>Activities</h4>
<p>Following activities are required.</p>
<ul>
<li>Run Maturity Model evaluation on standard tools.</li>
<li>Establish Personas for Dashboards</li>
<li>Estrablish Metrics by View/Persona</li>
</ul>
<p>At some point, build a <strong>Data Collection and Aggregation Tooling/Implementation</strong>.</p>
<h2><strong><em>Big List of Tools, Practises and Activities</em></strong></h2>
<p>What we have been doing so far, is basically running the <em>map</em> part of a map-reduce analysis. Aggregating all of the tools, practises and activities found above, we get the following big list.</p>
<h3>Tools / Practises</h3>
<ul>
<li>Git</li>
<li>Selenium</li>
<li>Build pipelines and CI</li>
<li>PowerShell</li>
<li>Azure CLI</li>
<li>Azure Dev/Test Labs</li>
<li>Azure Operations Management Services</li>
<li>Azure AppInsights.</li>
<li>Azure Application Resource Templates</li>
<li>VSTS</li>
<li>Google Analytics</li>
<li>NewRelic</li>
<li>ELK</li>
</ul>
<h1>Practises</h1>
<ul>
<li>Microservices</li>
<li>TDD</li>
<li>DDD</li>
<li>BDD</li>
<li>Automated Unit Tests</li>
<li>Automated Integration Tests</li>
<li>One Touch Build and Deploys.</li>
<li>Build Pipelines - Same builds on dev and test machines, Setup builds and Automated local deployment.</li>
</ul>
<h3>Activities</h3>
<ul>
<li><em><strong>There seems to be no standards in the world around Logging formats and Test reports</strong></em>.</li>
<li>Persona based metrics - <em>who needs what metrics?</em></li>
<li>Automation ROI graphs - <em>how to demonstrate?</em></li>
<li>How to enable specification to final product traceability?</li>
<li>Maturity Model evaluation on identified tools.</li>
<li>Establish Personas for Dashboards</li>
<li>Establish Metrics by View/Persona</li>
<li>Establish Data Collection and Aggregation Tooling/Implementation.</li>
</ul>
<p>This may not be exactly the list you come up with, but if you followed along on the exercise model, you have your own list.</p>
<p>I am leaving the reduce part of this operation out, as that will probably diverge for everyone. But, at its basic premise, evaluating your group's maturity model on each of these items and identifying the highest priority items should get you there. Multiple rounds of reviews from multiple stake-holders is the way forward now.  But no of items should '<em>reduce</em>' in reduce phase.</p>
<p>So there you go, now we have a set of starting points for a DevOps Strategy 101. All we have to do now is Go forth, and Iterate.</p>
<p>Oh, and of course, implement !</p>
<hr />
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="https://insen.github.io/blog/2017/09/24/Azure-AAD-with-Office-365/">
        Azure AD and Office 365 OAuth Integration via Postman
      </a>
    </h1>

    <span class="post-date">24 Sep 2017</span>

    <p>I spent last week answering a question. Is there a way to find available meeting times on a given user's Office 365 calendar next week? The short answer is <strong>yes</strong>.</p>
<h2>Longer answer.</h2>
<p>At work we have MSDN Azure subscriptions. These are linked to our organization's Azure Active Directory (AAD) and we can sign on to Azure with our Windows credentials. We also Office 365 accounts linked to our Exchange AD and Azure AD. I can seamlessly navigate to Office 365 on the browser after logging into Azure portal through my Windows account (OAuth magics). If this works for you too, then your Single Sign On (SSO) setup is also done.</p>
<p>The goal here is to understand how Azure OAuth authentication works when calling the outlook APIs through Azure AD. Preferably, I want to achieve this through raw HTTP calls, using just the browsers or Postman REST client, so that the HTTP based protocols and interactions are clear and open to visual inspection. In a nutshell, the steps are as follows.</p>
<ul>
<li>Create an Azure AD application / Service principal.</li>
<li>Redirect user to Exchange Active Directory for Authentication.</li>
<li>Return Auth Code to user after Azure AD, through OAuth, has authenticated against organization's Exchange AD.</li>
<li>Convert OAuth Code into Azure bearer token.</li>
<li>Call Microsoft Office APIs in SSO mode using token received above to retrieve the available meeting times for a employee given a specified time window.</li>
</ul>
<p>Now, many online resources already exist on this, yet getting all the pieces playing together was rough. So, we'll walk the route I did and hope that the eco-system clears itself up.</p>
<p>In the process, I will briefly touch on OAuth in Azure, Azure AD, Scopes and Resources in MS Online API, Azure Service Principals aka App registrations, App permissions aka OAuth <em>on-behalf-of consent</em> flow, Azure bearer tokens in Postman, JSON Web Tokens (JWT) and the Microsoft Graph explorer. Oh! and the Graph and Outlook sandboxes.</p>
<p><em>Note: In Azure, things change. The information here is of 24th Sept 2017.</em></p>
<p><em>For the rest you need an Azure subscription, an Office 365 account, and an Azure AD membership. You can have non work accounts for all three, but its a lot easier if your company admin has done the configuring for you. Blogs are the way to go here if you want to setup trial accounts for each.</em></p>
<h2>findMeetingTimes API</h2>
<p>Do such APIs exist? Well, yes, they do. Problem is, more than <strong><em>one</em></strong> exist.</p>
<h4>Outlook/Office 365 APIs</h4>
<p>Documentation link here - <a href="https://msdn.microsoft.com/en-us/office/office365/api/calendar-rest-operations#find-meeting-times">https://msdn.microsoft.com/en-us/office/office365/api/calendar-rest-operations#find-meeting-times</a>,
The API is shown below -</p>
<pre><code>POST https://outlook.office.com/api/{version}/me/findmeetingtimes
</code></pre>
<p>and there are <em>three</em> <em>version</em>s of it - <em>v1.0, v2.0, beta</em>.</p>
<p>Moreover, to use the API, the docs mention that we also need at least one of the following scopes -  <code>https://outlook.office.com/calendars.read.shared, wl.calendars, wl.contacts_calendars</code>. Scopes are an important concept in Azure auth governing permissions, and we'll see more of them in later sections.</p>
<p>The sandbox to play-around with all of this is here <a href="https://oauthplay.azurewebsites.net/">https://oauthplay.azurewebsites.net/</a>.</p>
<h4>Microsoft Graph APIs</h4>
<p>This is the second, latest and greatest option from Microsoft. Again, documentation is here - <a href="https://developer.microsoft.com/en-us/graph/docs/concepts/findmeetingtimes_example">https://developer.microsoft.com/en-us/graph/docs/concepts/findmeetingtimes_example</a>, the API looks like this</p>
<pre><code>POST https://graph.microsoft.com/v1.0/me/findMeetingTimes
</code></pre>
<p>and the sandbox (called MS Graph Explorer), is here - <a href="https://developer.microsoft.com/en-us/graph/graph-explorer">https://developer.microsoft.com/en-us/graph/graph-explorer</a>.</p>
<h4>Outlook vs Graph.</h4>
<p>So why two? When to use what?</p>
<p>Well previously MS had multiple APIs available - Office, Azure AD, etc. MS Graph is intended to unify all of these endpoints into a single REST-ful gateway for all of Microsoft's underlying platform APIs viz. Azure AD, Excel, Outlook, OneDrive, OneNote, SharePoint etc. It is not fully at par with existing APIs, but Microsoft's recommendation is to prefer MS Graph unless you need a feature which it does not have.</p>
<p>For current and future work, prefer MS Graph over other means.</p>
<h4>API Request body.</h4>
<p>In either case the POST body is the same, so that's a relief. A detailed request is given towards the end of this post.</p>
<p>So endpoints - Check.</p>
<p>Request Body and Response - Check.</p>
<p>Well, on to Azure AD and OAuth SSO, then.</p>
<h2>Azure Active Directory (AAD) and OAuth.</h2>
<p>Azure OAuth based authentication is a big and complex topic and cannot be covered adequately in a single blog post. Conceptually, the Azure OAuth flow is like <img src="/blog/img/posts/azureoauth.png" alt="this" />.</p>
<p><em>The diagram source and more documentation can be found at <a href="https://docs.microsoft.com/en-us/azure/active-directory/develop/active-directory-v2-protocols-oauth-code#main">https://docs.microsoft.com/en-us/azure/active-directory/develop/active-directory-v2-protocols-oauth-code#main</a>.</em></p>
<p>In our case, as mentioned before, the full authentication process needs the following -</p>
<ul>
<li>Create an Azure AD application / Service principal.</li>
<li>Redirect user to Exchange Active Directory for Authentication.</li>
<li>Return Auth Code to user after Azure AD, through OAuth, has authenticated against organization's Exchange AD.</li>
<li>Convert OAuth Code into Azure bearer token.</li>
<li>Call Microsoft Office APIs in SSO mode using token received above to retrieve the available meeting times for a employee given a specified time window.</li>
</ul>
<p>But lets look at the details, where the devils lurk.</p>
<h4>Theory - App Registration / Generate Service Principal</h4>
<p>First, someone needs to get authenticated. This, in Azure terms, is a Service Principal. This is achieved by registering an application with Azure AD, which gives us three important keys, the <em>tenantId, clientId</em> and the <em>clientSecret</em> after registration.
<em>For details about how to register an app, see  <a href="https://docs.microsoft.com/en-us/azure/active-directory/develop/active-directory-integrating-applications">https://docs.microsoft.com/en-us/azure/active-directory/develop/active-directory-integrating-applications</a>.</em></p>
<p>After registration, we save the following key-value pairs for subsequent use.</p>
<ul>
<li><em>tenantId</em>: guid looking code of the AD instance in your Azure subscription.</li>
<li><em>clientId</em>: guid looking code of the application being registered.</li>
<li><em>clientSecret</em>: guid looking key corresponding to a code we create in the application properties on Azure.</li>
</ul>
<p><em>Note : The clientSecret will be shown only once when creating a app property. If you don't note it down, you need to delete and recreate a key. It canot be recovered.</em></p>
<h4>Theory - Azure AD and OAuth.</h4>
<p>The OAuth dance is a two-step process here.</p>
<ul>
<li>Get a authentication code from the underlying authentication provider (OpenId, Active Directory).</li>
<li>Convert that code into a <a href="https://jwt.io">JSON Web Token</a>. For subsequent calls, this token needs to be used as the Authorization header.</li>
</ul>
<p><strong>Theory - Authorize API</strong></p>
<p>The following are the current logon/authorization endpoints for both v1.0 and v2.0.</p>
<pre><code>https://login.microsoftonline.com/{tenantId}/oauth2/authorize
https://login.microsoftonline.com/{tenantId/oauth2/v2.0/authorize
</code></pre>
<p>and a sample logon request with query parameters is as follows -</p>
<pre><code>GET https://login.microsoftonline.com/common/oauth2/v2.0/authorize?client_id=CLIENT_ID&amp;redirect_uri=http%3A%2F%2Flocalhost%2Fmyapp%2F&amp;response_type=code&amp;scope=openid+https://office.outlook.com/Calendars.Read.Shared
</code></pre>
<p>The query parameter definitions are given below -</p>
<pre><code>-   client_id: the clientId generated before during registering the app. This lets Azure know which app/service principal is requesting the logon.
-   redirect_uri: the location that Azure will redirect to once the user has granted consent to the app. This value must correspond to the value of Redirect URI used when *registering the app*.
-   response_type: the type of response the app is expecting. For the Authorization Grant Flow, this should always be the string `code`.
-   scope: a space-delimited list of access scopes that the app requires. For access to all outlook shared readable calendars in our Active Directory We have specified the following 
    - scope=openid+https://office.outlook.com/Calendars.Read.Shared
</code></pre>
<p><strong>Theory - Key things to remember</strong></p>
<ul>
<li>Previous versions had the domain <code>login.windows.net</code>. Some blogs use this. This is now not exposed, even though, based on inspection of HTTP headers, can be seen to be active in the background.</li>
<li>Also note we have two versions of the current endpoint as well - v1.0 and v2.0, and v2.0 has some differences from v1.0, viz., <em>v2.0 endpoint does not understand the query parameter 'resource' and throws an error</em>.</li>
<li>For multi-tenant apps, replace <em>tenantId</em> with <em>'common'</em>.</li>
<li>The keys given to us from Azure app registration are <strong><em>clientId, tenantId, clientSecret</em></strong>. However, in the authorize call, the API expects the query parameters as <em>underscore_separated</em>, i.e., as <strong><em>client_id, tenant_id, and client_secret</em></strong>. I got stuck here for a while too.</li>
</ul>
<p><strong>Theory - OAuth response</strong></p>
<p>The authorization takes the required query string parameters, in our case, returns an authentication code. This is one of the possible variations on the request.</p>
<p>Using OAuth, authentication is redirected to your organizations Windows Active Directory SSO page, so that you can log in with your Windows credentials.</p>
<p>It then returns the code to the <em>response_uri</em> specified. The <em>code</em> looks like this</p>
<pre><code>QABAAIAAAABlDrqfEFlSaui6xnRjX5Ef_{removed_lots_of_crazy_characters_here}_OSXEQcdFf2RLPAXbz30RgbyAA
</code></pre>
<h4>Theory - Scopes in brief.</h4>
<p>Scopes correspond to permissions which the account making the Rest API call will need to successfully interact with Azure resources. In our case, it the application corresponding to the <em>clientId</em> which needs the permissions, as we are logging on to our tenant as this client, i.e. we will use this <em>clientId</em> during the logon/authorize call.</p>
<p>Roughly speaking, we can think of an Azure Resource equals an domain viz. <code>office.outlook.com, graph.microsoft.com,</code> etc. Note that Azure resources can be a lot more granular though.</p>
<p>The application we registered can request these set of permissions after the logon page is past,
OR we can pre-allow these permissions to the application while registering. This option is the <em>OAuth On-Behalf-Of Consent Flow</em>.</p>
<p>A fuller discussion on scopes can be found at <a href="https://docs.microsoft.com/en-us/azure/active-directory/develop/active-directory-v2-scopes">https://docs.microsoft.com/en-us/azure/active-directory/develop/active-directory-v2-scopes</a>.</p>
<p>A key thing to remember is the difference between how scopes are provided for Outlook REST APIs at <code>outlook.office.com</code> vs. MS Graph at <code>graph.microsoft.com</code>. For Outlook - <em>resource</em> permissions (permissions for a particular URL) need to be specified in the query parameter in the format <code>https://url/permissions</code>. See example below.</p>
<pre><code>openid+offline access+https://outlook.office.com/Calendars.Read.Shared+https://outlook.office.com/Contacts.Read
</code></pre>
<p>For Graph API, the URL can be omitted, so the query param for MS Graph will be</p>
<pre><code>openid+offline access+Calendars.Read.Shared+Contacts.Read
</code></pre>
<p>We do not need <code>https://graph.microsoft.com</code> in the URL's <em>scope</em> parameter.</p>
<h3>Theory - Convert Auth Code To Bearer Token</h3>
<p>The second part of authentication is in converting the auth code into a JSON Web Token (see <code>https://jwt.io</code>). The base tokenization URL is</p>
<pre><code>POST https://login.windows.net/common/oauth2/token
</code></pre>
<p>The body is of type www-form-encoded and has the following key-value pairs.</p>
<pre><code>grant_type=authorization_code&amp;code={code from the authorize request}&amp;redirect_uri={reply url for your application}&amp;client_id={your application's client id in AAD}&amp;client_secret={your application's client secret}
</code></pre>
<p>The HTTP response is a JSON document of form -</p>
<pre><code class="language-JSON">{
    &quot;token_type&quot;: &quot;Bearer&quot;,
    &quot;scope&quot;: &quot;Calendars.Read Calendars.Read.All Calendars.Read.Shared offline_access&quot;
    &quot;expires_in&quot;: &quot;3599&quot;,
    &quot;ext_expires_in&quot;: &quot;262800&quot;,
    &quot;expires_on&quot;: &quot;1506082448&quot;,
    &quot;not_before&quot;: &quot;1506078548&quot;,
    &quot;resource&quot;: &quot;https://outlook.office.com/&quot;,
    &quot;access_token&quot;: &quot;{removed-use your own tokens}&quot;,
    &quot;refresh_token&quot;: &quot;{removed-use your own tokens}&quot;,
    &quot;id_token&quot;: &quot;{removed-use your own tokens}&quot;
}
</code></pre>
<p>A access token is as per the JWT specification. Encoded, it looks like this - <code>eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1-{removed_lots_of_chars_here}-CTN2M3GXpo53GaXko0FgwPFjPA</code></p>
<p>However, this contains a lot of information. When decoded (via <a href="http://jwt.io">JWT.io</a>), we can see the information it contains -</p>
<pre><code class="language-JSON">{
  &quot;aud&quot;: &quot;https://outlook.office.com/&quot;,
  &quot;iss&quot;: &quot;https://sts.windows.net/{tenantId}/&quot;,
  &quot;iat&quot;: 1506070849,
  &quot;nbf&quot;: 1506070849,
  &quot;exp&quot;: 1506074749,
  &quot;acr&quot;: &quot;1&quot;,
  &quot;aio&quot;: &quot;Y2VgYHjuJj1PSJv1qLb8h9Y9s3wvRa5NSegLEFNqsHqx9d6LHgcA&quot;,
  &quot;amr&quot;: [
    &quot;pwd&quot;
  ],
  &quot;appid&quot;: &quot;registered_app_id&quot;,
  &quot;appidacr&quot;: &quot;1&quot;,
  &quot;e_exp&quot;: 262800,
  &quot;enfpolids&quot;: [],
  &quot;family_name&quot;: &quot;my_family_name&quot;,
  &quot;given_name&quot;: &quot;my_first_name&quot;,
  &quot;ipaddr&quot;: &quot;219.91.160.98&quot;,
  &quot;name&quot;: &quot;my_full_name&quot;,
  &quot;oid&quot;: &quot;oid&quot;,
  &quot;onprem_sid&quot;: &quot;S-1-5-21-1708537768-789336058-725345543-1974208&quot;,
  &quot;puid&quot;: &quot;1003BFFD870F4BB4&quot;,
  &quot;scp&quot;: &quot;Calendars.Read Calendars.Read.All Calendars.Read.Shared Contacts.Read Contacts.Read.Shared offline_access&quot;,
  &quot;sub&quot;: &quot;5M4_YhrPEtd558TCLIWVHGxhgKyxqsctKvtjYpnEx1o&quot;,
  &quot;tid&quot;: &quot;tenantId&quot;,
  &quot;unique_name&quot;: &quot;my logon mail id here&quot;,
  &quot;upn&quot;: &quot;my logon mail id here&quot;,
  &quot;ver&quot;: &quot;1.0&quot;
}
</code></pre>
<h3>Theory - MS Office API, REST call.</h3>
<p>Most of the nitty-gritties should have been worked out of the way now. We just need to call the Outlook REST API as follows -</p>
<pre><code>POST https://outlook.office.com/api/{version}/me/findmeetingtimes
</code></pre>
<p>Add the following HTTP headers to the request</p>
<ul>
<li>Content-Type : application/json</li>
<li>Authorization : bearer <em>{token_returned_by_token_endpoint}</em></li>
</ul>
<p><strong>NOTE</strong> : Note the string <em>bearer</em>, followed by a space, in front of the token. I struggled for a long time at this step before figuring this out.</p>
<p>And voila. everything works. or does it? Since practise beats theory everytime, let's get down to browsers and POSTMAN.</p>
<h2>Practise - Putting it all together.</h2>
<p>Okay, brass-tacking time now.</p>
<h4>Practise - Add Application into AD.  Save the <em>tenantId, clientId and clientSecret</em>.</h4>
<ul>
<li>Added a new application called 'Postman' in the linked Azure Active Directory through Azure portal.</li>
<li>Specify 'Read User and Shared Calendars' in the permissions panel, and explicitly granted those permissions. Through this, we are implementing <em>OAuth On-Behalf-Of-Consent flow</em>. Otherwise, we would have an intermediate screen after entering our Windows credentials where we would have to accept the use of these permissions.</li>
<li>Add two response_uri, one for Postman REST client to use the response auth code, and one to see the raw http auth request and response in a browser window myself. For Postman I added <code>https://www.getpostman.com/oauth2/callback</code>, as per Postman REST client requirements, and a second one, <code>http://localhost/myapp/</code> for my browser based calls.</li>
</ul>
<p>Once done, we keep the following key-values (<em>not exact, of course</em>) handy.</p>
<pre><code class="language-JSON">tenantId : fea858f0-512d-4649-8228-d78fd9ef3c7f
clientId : 794b53a6-e176-4185-92fe-617dd8512db5
clientSecret: MyQt+7mKw/Vz7p6XjHRfBOe68ffWvjmjVhJP69K1dec!=
</code></pre>
<h4>Practise - Invoke Azure Authorize API.</h4>
<p>The full <code>GET</code> request for my use case is as follows. Paste this into a browser window which is not already signed into azure.</p>
<pre><code>https://login.microsoftonline.com/common/oauth2/authorize?client_id=794b53a6-e176-4185-92fe-617dd8512db5&amp;redirect_uri=http%3A%2F%2Flocalhost%2Fmyapp%2F&amp;response_type=code&amp;scope=https://outlook.office.com/calendars.read.shared
</code></pre>
<p>Important points to remember</p>
<ul>
<li>Note I have used the endpoint 'common'.</li>
<li>Note that I have used v1.0 endpoint. v2.0 did not work for me. The Authorize call succeeds, but the token call fails with a version mismatch error.</li>
<li>Note the callback used here 'http://localhost/myapp/'. This was one of the endpoints registered with AD as the call back URI for the 'Postman' application/service principal.</li>
<li>Ensure that all URLs mentioned are escaped properly. in the above the <em>request_uri</em> is escaped right, but the scope one isn't. It still works, but try not to do this.</li>
<li>Ensure that all URLs end with a trailing slash. This one causes a nasty error with an incomprehensible error message.</li>
<li>Add the scopes correctly and ensure that the corresponding permissions are granted in Azure portal to the Application.</li>
</ul>
<p>When the call returns, it shows me a browser page with HTTP 404. That is expected, as the actual URL does not exist. The URL that can be seen in the browser address bar, is like this -</p>
<pre><code>http://localhost/myapp/?code=QABAAIAAAABlDrqfEFlSaui6-{removed_lots_of_chars_here}-e3e45d8d4
</code></pre>
<p>Note that this is the callback URL specified during application registration. The auth code is appended to the querystring. We will need this code subsequently.</p>
<h4>Practise - Invoke Azure token API</h4>
<p>In POSTMAN, Create a new <code>POST</code> request to the following endpoint</p>
<pre><code>https://login.microsoftonline.com/common/oauth2/token
</code></pre>
<p>Create a request body as type <code>x-www-form-urlencoded</code>. In the POSTMAN bulk-edit mode, add the following JSON parameters to it.</p>
<pre><code>client_id: 794b53a6-e176-4185-92fe-617dd8512db5
scope: https://outlook.office.com/calendars.read.shared/
resource: https://outlook.office.com/
code: QABAAIAAAABlDrq-{removed_lots_of_chars_here}-UassQOSXEQcdFf2RLPAXbz30RgbyAA
redirect_uri: http://localhost/myapp/
grant_type: authorization_code
client_secret: MyQt+7mKw/Vz7p6XjHRfBOe68ffWvjmjVhJP69K1dec!=
</code></pre>
<p>Fire the request. We should get the following response.</p>
<pre><code>{
    &quot;token_type&quot;: &quot;Bearer&quot;,
    &quot;scope&quot;: &quot;Calendars.Read Calendars.Read.All Calendars.Read.Shared Contacts.Read Contacts.Read.Shared offline_access&quot;,
    &quot;expires_in&quot;: &quot;3599&quot;,
    &quot;ext_expires_in&quot;: &quot;262800&quot;,
    &quot;expires_on&quot;: &quot;1506082448&quot;,
    &quot;not_before&quot;: &quot;1506078548&quot;,
    &quot;resource&quot;: &quot;https://outlook.office.com/&quot;,        
    &quot;access_token&quot;: &quot;myJ0eXAiOiJKV1Qi-{removed_lots_of_chars_here}-ukX3nBlRfzh6Sg&quot;,        
    &quot;refresh_token&quot;: &quot;QABAAAAAAABlDrq-{removed_lots_of_chars_here}-uoBFATkE6ZJHyAA&quot;,        
    &quot;id_token&quot;: &quot;yJ0eXAiOiJKV1QiL-{removed_lots_of_chars_here}-SIsInZlciI6IjEuMCJ9.&quot;
}
</code></pre>
<h4>Practise - Invoke Outlook REST API.</h4>
<p>Again in POSTMAN, create another <code>POST</code> request for the following URI.</p>
<pre><code>https://outlook.office.com/api/v2.0/me/findmeetingtimes
</code></pre>
<p>Add the HTTP headers</p>
<pre><code>Content-Type: application/json,
Authorization: bearer myJ0eXAiOiJKV1-{removed_lots_of_chars_here}-PNukX3nBlRfzh6Sg
</code></pre>
<p><strong>Note</strong> the space between bearer and the rest of the <em>access_token</em> returned by the previous token call.</p>
<p>Add the following as raw request JSON -</p>
<pre><code class="language-json">{ 
&quot;Attendees&quot;: [ 
    { 
    &quot;Type&quot;: &quot;Required&quot;,  
    &quot;EmailAddress&quot;: { 
        &quot;Name&quot;: &quot;my_name&quot;,
        &quot;Address&quot;: &quot;my_mail_id&quot; 
    } 
    },
{ 
    &quot;Type&quot;: &quot;Optional&quot;,  
    &quot;EmailAddress&quot;: { 
        &quot;Name&quot;: &quot;other_name&quot;,
        &quot;Address&quot;: &quot;other_mail_id&quot; 
    } 
    }  
],  
&quot;TimeConstraint&quot;: { 
    &quot;ActivityDomain&quot;:&quot;Work&quot;,
    &quot;Timeslots&quot;: [ 
    { 
        &quot;Start&quot;: { 
        &quot;DateTime&quot;: &quot;2017-09-22T07:00:00&quot;,  
        &quot;TimeZone&quot;: &quot;Pacific Standard Time&quot; 
        },  
        &quot;End&quot;: { 
        &quot;DateTime&quot;: &quot;2017-09-23T17:00:00&quot;,  
        &quot;TimeZone&quot;: &quot;Pacific Standard Time&quot; 
        } 
    } 
    ] 
},  
&quot;MeetingDuration&quot;: &quot;PT1H&quot; 
} 
</code></pre>
<p>Fire the request.  The outlook API should now return a valid response from Office 365.</p>
<p>If you want to try out the equivalent graph API, you need to do a fresh authentication. This time use the scopes as required for MS Graph <em>(no url, just the scope value)</em>. Then use this Auth Code to get a fresh bearer token. Using this token for a call to the MS Graph API should work. It did work for me without any hassles.</p>
<p>And that's all of it. We can go home now.</p>
<hr />
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="https://insen.github.io/blog/2017/08/29/getting-started-github-pretzel/">
        Getting started with Github Pages and Pretzel
      </a>
    </h1>

    <span class="post-date">29 Aug 2017</span>

    <p>As I mentioned in my <a href="http://insen.github.io/blog/2017/08/29/helloblog/">'hello-blog'</a> post, my search for
blogging tools ended at Github Pages and Pretzel. In this post, I will outline the process of setting up a
blog using Github pages, Pretzel, Hyde and Markdown, using what I learnt while setting up this one.</p>
<h3>The Goal.</h3>
<p>The goal here is a system which has the following publish-a-blog sequence -</p>
<ul>
<li>Write the blog in as close to english as possible. We use Markdown (filename.md) for close-to-english text files.</li>
<li>Add the file into a specific directory on local machine.</li>
<li>Review add/edited blog-site and added/edited blog-post without internet connectivity. Rinse and repeat as needed.</li>
<li>Check in all updates (aka backup). Enter Github - On successful check-in, online blog is automatically updated with new content. (Only this step needs internet connectivity).</li>
</ul>
<p>Essentially, its very developer friendly. This process emulates the <strong><em>code, build, test, deploy</em></strong> cycle of software development.</p>
<h3>The Pieces.</h3>
<p>The infrastructure</p>
<ul>
<li>A <strong>Github project pages repository</strong> which will have
<ul>
<li>A template project for a web-site, which I chose to be <strong>Hyde</strong>. Why?
<ol>
<li>I liked it.</li>
<li>It is a Jekyll theme. Github pages default is Jekyll. I avoided using Jekyll because of reasons cited later, But staying close to defaults seemed a good idea.	</li>
</ol>
</li>
<li>A directory within the repository named 'docs' (as per Github rules) holding the pre-assembled auto-generated and checked-in web-site. Github pages automatically serves this web-site from a public Url.</li>
</ul>
</li>
<li><strong>Pretzel</strong> to build/rebuild the web-site template, new/edited posts and generate/preview the updated web-site while offline. Some batch files for the builds with Pretzel commands, so that the process is seamlessly repeatable.</li>
<li><strong>Git</strong>, to push the updates to the template, the posts and to the generated web-site (docs folder) into the repo and the publishable version into the docs folder. <em>(Note that we didn't say anything about copying anything over to docs folder - Pretzel build scripts take care of that.)</em></li>
<li>Oh, and I almost forgot. <strong>Visual Studio Code</strong> is the text editor. Pick whichever you like.</li>
</ul>
<p><em>(Note - If you don't have a github account, this is a good time to create one. Also, if you don't know Git, much of this blog won't make sense to you. if you really, really want to blog, this is a good alternative option <a href="http://tumblr.com">tumblr</a>)</em>.</p>
<h3>Github and <a href="https://help.github.com/articles/user-organization-and-project-pages/">Github Pages</a></h3>
<p>Github Pages are a feature inbuilt into Github which enables you to host static web-sites with minimum effort. There are a few different flavors.</p>
<h4>User Pages</h4>
<p>If your github account is <strong>acc</strong>, Create a new repository named as <strong>acc</strong> (same as the account name). A public web-site with no content is available at http://<strong>acc</strong>.github.io.</p>
<p>Add a index.html with only the text 'Hello World' into the 'master' branch.  You should see 'Hello World' in your browser from http://<strong>acc</strong>.github.io/.</p>
<h4>Organization Pages</h4>
<p>Similar to user pages except the repo is at the organization level, and has the same name as the
organization. Gets published(approximately) at http://github.com/<strong>organizationname</strong>. *Check with official Github documentation as I didn't investigate this much.</p>
<h4>Project Pages</h4>
<p>If your github account is <strong>acc</strong>, viz, your Github account is at https://<strong>acc</strong>.github.com, and you add a new repository named as <strong>repo</strong>, the Project pages site with no content is available at https://<strong>acc</strong>.github.io/<strong>repo</strong></p>
<p>Add a folder called 'docs' in repo in the master branch.</p>
<p>Add a <strong>index.html</strong> with just the text 'Hello World' into the 'docs' folder. This automatically gets published as http://<strong>acc</strong>.github.io/<strong>repo</strong>. You should see 'Hello World' in your browser from this site.</p>
<p>These sites are available at a per-repository level. They can also be configured so that the web-site is geing served either from master branch, from a top level folder in the master branch named as <strong>docs</strong> or a branch specifically named as <strong>gh-pages</strong>.</p>
<p>I am using the <strong>docs</strong> option above.</p>
<h4>Other Things...</h4>
<p>Note that it is perfectly possible to have user-pages, organization-pages and project-pages in the same account. Given that the user account is <strong>acc</strong>, the organization name is <strong>organizationname</strong>, and the project repo name is <strong>repo</strong>, the following public web-sites will be available.
-	http://<strong>acc</strong>.github.io/  as the User Page Site.
-	http://github.com/<strong>organizationname</strong> as an Organization Page Site
-	http://<strong>acc</strong>.github.io/<strong>repo</strong>  as a Project Page Site</p>
<p>The site can be a Jekyll based, <strong>OR</strong> a plain vanilla html website but with with an index.html at the top level of the site. I presume how this works is this - Github passes a http call to the site url through a web-server which can process <a href="http://liquid.org">Liquid</a> - a html templating engine. This engine passes on plain vanilla html as is, so html spec based content just flows through that web server. We are using this approach as we are pre-building the web-site as a collection of static html pages.</p>
<p>If using Jekyll, you need to create a Jekyll based website in the repo and branch as per your choice from the page types - user, organization or project. Github's Jekyll based build process will probably do the Jekyll builds on your behalf before publishing online. More details about Github's inbuilt support for Jekyll publishing can be found at <a href="https://help.github.com/articles/user-organization-and-project-pages/">here</a>.</p>
<h3>Hello <a href="https://Github.com/Code52/pretzel">Pretzel</a> <em>(and Static-site generators)</em>!</h3>
<p>Pretzel is a open source, static-site generator in .NET.</p>
<p>Maybe the first question to address is how many of these there are? <a href="https://www.staticgen.com/">Take a look</a>. When it comes to frameworks, We are living in a world of plenty these days.</p>
<p>What do they do? Well, basically a static site generator, especially the ones targeting blogging, take a bunch of layout templates (e.g. site-header.html, sidebar.html, footer.html), your CSS stylesheets, your Javascript, and your posts (usually in markdown, but based on support you could probably use any syntax - markdown, yaml, plain html, razor) - and processes them to a colection of plain vanilla HTML/CSS/Javascript pages - one for each post. Each page generated is a complete and self-contained html page, combining all the common layout templates, the CSS, the  Javascript and the Markdown content, with links between pages and navigation.</p>
<p>I picked Pretzel because it is written in C#. I know C# well so I can read the code, debug or enhance Pretzel if I ever so require. (Other possible options included <a href="http://wyam.io">Wyam</a>, and <a href="https://github.com">Sandra.Snow</a>).</p>
<p>Now Pretzel tries to keep as close as possible to Jekyll. Considering I am looking for a offline Jekyll replacement, Pretzel seemed appropriate.</p>
<p>And with Pretzel I can build/rebuild/run the entire site on my local machine with minimal fiddling (Which Jekyll setup, debug, or enhancement will all force me to do, and all in Ruby). As a .NET developer, my primary machine is usually all set to do just about anything with the CLR. Once testing is done, all I need to do is copy the local machine site folder into the folder from which Github serves project pages (the <strong>'docs'</strong> folder under Github repository root). With build scripts, I can automate this step. When I check-in to Github, after allowing some time for Github to build the site and CDN propagation to happen, the latest content comes up on the public site.</p>
<p>For further details, check out the <a href="https://Github.com/Code52/pretzel/wiki">Pretzel wiki</a>.</p>
<h3>Setup</h3>
<h4>Setting up the repository in Github portal.</h4>
<p>Do the following to setup your Github blogging. This method sets up a Project Site as the blog site.</p>
<ul>
<li>Create a Github account, viz. <strong>acc</strong>.</li>
<li>Create a repository in github, viz. <strong>repo</strong>. I created https://github.com/insen/blog.</li>
<li>Git clone into local machine. This is where you will be adding your site.
<ul>
<li>Add a <strong>docs</strong> folder. <em>(Name needs to be exact)</em>.
<ul>
<li>Add an index.html with the text 'Hello world'.</li>
</ul>
</li>
</ul>
</li>
<li>Push to Github.</li>
<li>Goto Github repository settings, Gh-Pages section - Select 'master branch/docs folder'.</li>
<li>Check <a href="#">https://<strong>acc</strong>.github.io/repo/</a> - the contents of index.html should be visible in your browser.</li>
</ul>
<p>And that's it. The blog post you are currently reading at <a href="https://insen.github.io/blog/">https://insen.github.io/blog/</a> has been built in the same fashion, though we are still missing a few steps yet - We need to setup pretzel and then make our site look decent. But reversing th order makes things easier, So onto Hyde first, then Pretzel.</p>
<h4>Importing Hyde to local machine.</h4>
<p>Hyde is a pre-built theme for Jekyll. Since Pretzel closely follows Jekyll paradigms, It should work without issues, or so I thought. I was mostly correct. All we have to do here is git clone the <a href="https://github.com/poole/hyde">Hyde repository at Github</a>.</p>
<p>The reason we need this is that the basic site created by Pretzel is quite horrible, both aesthetically and structurally. I started looking for something that works from an aesthetic point of view, but as close to Jekyll as possible, which led me to <a href="https://github.com/poole/hyde">Hyde</a>.</p>
<h4>Setting up Pretzel on local machine and basic usage.</h4>
<p>Setting up Pretzel is quite straight forward. Get Pretzel from <a href="https://github.com/Code52/pretzel">here</a>, <strong>OR</strong> use Chocolatey - a package manager for windows. To use Chocolatey, install Chocolatey from <a href="https://chocolatey.org/">here</a>, and on an elevated command prompt or powershell console, run the command</p>
<pre><code class="language-batch">	choco install pretzel
</code></pre>
<ul>
<li>To create a basic site for you. The command details are <a href="https://Github.com/Code52/pretzel/wiki">here</a>. You can
lookup the various possible options.</li>
</ul>
<pre><code class="language-batch">	pretzel create [options]
</code></pre>
<ul>
<li>Bake the site - means generate the output website and put it into a default folder. Usually named <strong>_site</strong> and located at project root level. The command details are <a href="https://Github.com/Code52/pretzel/wiki">here</a>. I will use the following version.</li>
</ul>
<pre><code class="language-batch">	pretzel bake 
		--source=&quot;c://srcpath&quot; 
		--destination=&quot;d://dpath&quot; 
		--cleantarget
</code></pre>
<ul>
<li>Test the site</li>
</ul>
<pre><code class="language-batch">	pretzel taste 
		--source=&quot;c://dpath&quot; 
		--port=8001
</code></pre>
<p><em>Important note</em> - the source directory in <em>'taste'</em> command is the destination directory in <em>'bake'</em> command. This is what we are using. For other options, check Pretzel wiki.</p>
<p>I will be creating batch scripts for the <em>(bake)</em> and <em>(taste)</em> snippets which will be useful.</p>
<h3>Getting jiggy with it.</h3>
<ul>
<li>Delete the contents of your repository (except docs folder), and then copy the entire contents of the hyde repo into your blog repo.</li>
<li>Run the Pretzel bake command from a prompt at the repository root folder with no command-line args. Pretzel should create a folder called <strong>_site</strong> under repository folder. It does NOT. It does this instead.</li>
</ul>
<pre><code class="language-c#">	Unhandled Exception: Pretzel.Logic.Exceptions.PageProcessingException: Failed to process E:\work\blogging\blog\_site\201
	2\02\07\example-content\index.html, see inner exception for more details ---&gt; DotLiquid.Exceptions.SyntaxException: Unknown tag 'gist'
		at DotLiquid.Block.UnknownTag(String tag, String markup, List`1 tokens)
		at DotLiquid.Block.Parse(List`1 tokens)
		at DotLiquid.Document.Initialize(String tagName, String markup, List`1 tokens)
		at DotLiquid.Template.ParseInternal(String source)
</code></pre>
<p>Why? The reason here is that a sample post in the _posts folder contains, among other bits, the following content</p>
<blockquote>
<p>{&#37; gist 5555251 gist.md &#37;}</p>
</blockquote>
<p>And this does not work in Pretzel.</p>
<p>Why again? Because Hyde is a Jekyll theme, and Jekyll has a parser for the <strong>gist</strong> command. Pretzel does NOT. Delete this line from the post.</p>
<p><em>(However, this also means, you have to figure out an alternative way to embed gists in your post, if you need to)</em>.</p>
<ul>
<li>
<p>Run <strong>bake</strong> again with no parameters. Pretzel uses the current directory as the source directory and creates the web-site. Now, <strong>bake</strong> should succeed, and you should see a sub-folder called <strong>_site</strong>. This contains your entire blog site.</p>
</li>
<li>
<p>Delete the <strong>CNAME</strong> file from the repository folder as well as the generated <strong>_site</strong> folder *(This causes issues   if you don't have a top level domain name. And no, you CANNOT point this to the Github site url).</p>
</li>
<li>
<p>Change <strong>index.html</strong>. This file should be in the <strong>repo</strong> directory.</p>
<ul>
<li>
<p>There should be a line towards the top. md <code>\{\% for post in paginator.posts \%\}</code>. Change 'paginator' to 'site'. Paginator is a Jekyll plugin and does NOT work in Pretzel. No posts show up if we retain paginator.</p>
</li>
<li>
<p>There should be a line a little below the above <code>&lt;a href=&quot;\{\{ post.url \}\}&quot;&gt;</code>. Change this to <code>&lt;a href=&quot;\{\{ post.url | prepend: site.baseurl }}&quot;&gt;</code>. Navigation between posts does not work otherwise.</p>
</li>
</ul>
</li>
<li>
<p>Update the config.yml. A config.yml is given below. I changed the <strong>'connect'</strong> and its sub-items. These fields are used in the Liquid based html templates, viz. <code>&lt;span&gt;\{\{ site.title }}&lt;/span&gt;</code> or <code>&lt;span&gt;\{\{ site.connect.github }}&lt;/span&gt;</code>, etc. The sections marked as <em>(Setup)</em> in ths file have to be filed in and be accurate. They are used to generate the site.</p>
</li>
</ul>
<blockquote>
<p>  <em>(Note - In code snippets above and config.yml file below the 'slash' before 'curly braces', 'percent' or 'hash' 	symbol are extra. The 'slash' is not part of actual code. it was needed to escape Liquid processing)</em>.</p>
</blockquote>
<pre><code class="language-yml">\# Dependencies
markdown:         redcarpet
highlighter:      pygments

\# Permalinks
permalink:        pretty
relative_permalinks: true

\# Setup
title:            'Some text'
tagline:          'Some text'  
description:      'Some text'
url:              'your blog url after publication - use https if https expected, else use http'
baseurl:          'your blog url after publication - use https if https expected, else use http. Could be same or different from previous'

author:
  name:           'a name'
  url:            'a url'

paginate:         5

\# Custom vars
version:          1.0.0

connect:
  github:          '@github'
  linkedin:        '@linkedin'
  email:           '@email'

exclude:
  - docs\
  - .gitignore
  - .git
  - pbake.bat
  - ptaste.bat 
</code></pre>
<p><em>(Note - Also for each line which begins with 'hash' is preceded by a 'slash'. the 'slash' is not part of config.yml. it was needed to escape markdown processing)</em>.</p>
<ul>
<li>
<p>Run <strong>taste</strong> command as specified above from the repository directory. This command should run, open a browser on local machine and show you the sample posts (ref - we removed the 'gist' tag from one of them).</p>
</li>
<li>
<p>Bake and taste the site again - Check the _site and the docs folder. There should be no recursive folder patterns. <em>(Note - this means that the bake and taste commands you used are correct with source and destination file names and other options. Otherwise your site generation times, and github check-in times, and github repo size will exponentially increase with the number of bakes. The two example commands given in usage section are correct except for file-names and avoid the recursive folders issue. I added these two commands as batch files to my repo - pbake.bat and ptaste.bat. These are my build files. Also, since the pretzel bake output is already redirected to the 'docs' folder in the batch files, I don't have to manually copy anything)</em>.</p>
</li>
<li>
<p>Check-in to Github.</p>
</li>
</ul>
<h3>Next is what?</h3>
<p>There's quite a bit left to do -</p>
<ul>
<li>A header</li>
<li>Landing site should show a list of posts, not posts and post-content.</li>
<li>Disqus integration.</li>
<li>Google Analytics integration.</li>
<li>Tag cloud.</li>
<li>Maybe CNAME and site search.</li>
</ul>
<p>But for now, this blog seems to be showing up on the internet. If you followed along this far with no problems, you should also be good to go.</p>
<p>Go forth, and typo. <em>(pssst !! pun intended)</em>.</p>
<h3>Additional resources</h3>
<ul>
<li><a href="https://www.freeformatter.com/html-entities.html">Free Formatter</a> for html encoding.</li>
<li><a href="https://daringfireball.net/projects/markdown/syntax">Markdown Syntax</a> for reference.</li>
<li><a href="https://gist.githubusercontent.com/VEnis/7465176/raw">Markdown Sample</a> which works in Github.</li>
</ul>
<hr />
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="https://insen.github.io/blog/2017/08/29/helloblog/">
        Blog like you are coming home.
      </a>
    </h1>

    <span class="post-date">29 Aug 2017</span>

    <h2>Hello blog, eh, I mean, world!</h2>
<p>As far back as I can remember, I have always been writing. However, I have never blogged. Probably because I preferred the diary and the pen. Having caught a lot of flak for it from my friends, well-wishers, colleagues and bosses alike over the years, I finally decided to fix that.</p>
<p>But, I had conditions -</p>
<ul>
<li>Not much overhead beyond the writing.</li>
<li>Retain maximum possible control over content, display and offline support.</li>
<li>Also, I have a technical background so I wanted to learn something out of it.</li>
</ul>
<p><em>Note :</em> The first and the third above may be self-contradictory, but I am ok with that.</p>
<p>So I started looking. Now, traditional blogging platforms end up keeping my data. I didnt like that.
Plus I havent seen good web-based blog editors. So the web based blogs weren't options I was inclined to
try first. Having encountered github blogging in the past and liked what I saw, I investigated it again.
Soon, it was clear that the simplicity of a static site was hard to beat. The catch was, Github integrates
Jekyl. Now Jekyll is good, but getting Jekyll on windows involves some fiddling and a good deal of ruby.
Having recently gone through .Net Core, Scala, Spark, Azure and NodeJs recently in quick succession, I had
no appetite for another. A little more looking, and I found <a href="https://Github.com/Code52/pretzel">Pretzel</a> - a .NET
based static-site generator, plus extras.</p>
<p>Thus I settled. <em>(The living-happily-there-ever-after-question has no answers yet.)</em></p>
<ul>
<li>Blogging should be simple. Hence Github pages.</li>
<li>Blogging i.e. content, display and offline mode should remain in blogger's control. Hence pretzel and
not jekyll. Also see <a href="https://thomasfreudenberg.com/archive/2016/05/16/from-jekyll-to-pretzel/">here</a> for
more details.</li>
<li>And I get to dig into pretzel and maybe learn about static-site-generators.</li>
<li>Oh, and I rather liked the <a href="https://github.com/poole/hyde">Jekyll Hyde Theme</a>.</li>
</ul>
<p>Therefore, this blog is being served from a Github-pages static site, with the site template taken from
the Jekyll theme called Hyde, actually being generated by Pretzel on local machine and getting checked
into Github.</p>
<p>I just need to figure out markdown now, and then technically speaking, I am back to <strong>write, build,
test and deploy</strong>. Blog or not, thats like coming home.</p>
  </div>
  
</div>

<div class="pagination">
  
    <span class="pagination-item older">Older</span>
  
  
    <span class="pagination-item newer">Newer</span>
  
</div>
    </div>

  </body>
</html>
